{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53fa78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9e07130",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_file = '../data/train.en'\n",
    "sanskrit_file = '../data/train.sn'\n",
    "\n",
    "START_TOKEN = ''\n",
    "PADDING_TOKEN = ''\n",
    "END_TOKEN = ''\n",
    "\n",
    "sanskrit_vocabulary = [\n",
    "    START_TOKEN, ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '?', ':', ';',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "\n",
    "    # Independent vowels\n",
    "    'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ॠ', 'ऌ', 'ॡ', 'ए', 'ऐ', 'ओ', 'औ',\n",
    "    \n",
    "    # Consonants\n",
    "    'क', 'ख', 'ग', 'घ', 'ङ',\n",
    "    'च', 'छ', 'ज', 'झ', 'ञ',\n",
    "    'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
    "    'त', 'थ', 'द', 'ध', 'न',\n",
    "    'प', 'फ', 'ब', 'भ', 'म',\n",
    "    'य', 'र', 'ल', 'व',\n",
    "    'श', 'ष', 'स', 'ह',\n",
    "\n",
    "    # Vowel signs\n",
    "    'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'े', 'ै', 'ो', 'ौ',\n",
    "\n",
    "    # Other signs\n",
    "    'ं', 'ः', 'ँ', '्',  # virama, anusvara, visarga, chandrabindu\n",
    "    '।', '॥',  # danda marks\n",
    "\n",
    "    # Special tokens\n",
    "    PADDING_TOKEN, END_TOKEN\n",
    "]\n",
    "\n",
    "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                        ':', '<', '=', '>', '?', '@', \n",
    "                        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', \n",
    "                        'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', \n",
    "                        'Y', 'Z',\n",
    "                            # Diacritic letters used in IAST transliteration\n",
    "    'ā', 'ī', 'ū', 'ṛ', 'ṝ', 'ḷ', 'ḹ',\n",
    "    'ṅ', 'ñ', 'ṭ', 'ḍ', 'ṇ',\n",
    "    'ś', 'ṣ', 'ḻ',\n",
    "\n",
    "    # Capital versions (if any)\n",
    "    'Ā', 'Ī', 'Ū', 'Ṛ', 'Ṝ', 'Ḷ', 'Ḹ',\n",
    "    'Ṅ', 'Ñ', 'Ṭ', 'Ḍ', 'Ṇ',\n",
    "    'Ś', 'Ṣ', 'Ḻ',\n",
    "                        '_',\n",
    "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                        'y', 'z', \n",
    "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09b28af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ş', 'ī', 't', 'ā']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Şītā'\n",
    "list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97602041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['म', 'म', 'ै', 'व', 'ा', 'भ', 'ि', 'म', 'ु', 'ख', 'ं']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'ममैवाभिमुखं'\n",
    "list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6dd563bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मै'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'म'+ 'ै'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a46af301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/train.en'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fe7f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_to_sanskrit = {k:v for k,v in enumerate(sanskrit_vocabulary)}\n",
    "sanskrit_to_index = {v:k for k,v in enumerate(sanskrit_vocabulary)}\n",
    "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59ad627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(english_file, 'r') as file:\n",
    "    english_sentences = file.readlines()\n",
    "with open(sanskrit_file, 'r') as file:\n",
    "    sanskrit_sentences = file.readlines()\n",
    "\n",
    "# Limit Number of sentences\n",
    "TOTAL_SENTENCES = 100000\n",
    "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
    "sanskrit_sentences = sanskrit_sentences[:TOTAL_SENTENCES]\n",
    "english_sentences = [sentence.rstrip('\\n') for sentence in english_sentences]\n",
    "sanskrit_sentences = [sentence.rstrip('\\n') for sentence in sanskrit_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb7c2a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When Şītā, having a husband although seeming as if she had none, was putting on the ascetic guise, the people got into a wrath and exclaimed, “O Dasaratha, fie on you!\"',\n",
       " 'Aggrieved at the uproar that arose there in consequence, the lord of earth banished from his heart all regard for life, virtue, and fame. And sighing hot, that descendant of Ikşvāku spoke to that wife of his, saying, O Kaikeyi, Sītā deserves not to go in a Kuća dress.',\n",
       " 'Tender, and youthful, and worthy of happiness, she is by no means capable of living in the forest. My spiritual guide has spoken the truth.',\n",
       " 'Whom has this one injured that, being the daughter of the foremost of kings, she like a female ascetic, wearing a meagre garb in the presence of all, will (repair to the woods and) remain there like a beggar destitute of everything?',\n",
       " \"Let Janaka's daughter leave off her ascetic guise. This is not the promise that I had made to you before. Let the princess go to the forest in comfort, furnished with all sorts of gems.\",\n",
       " 'My sands run out; by me has this cruel promise been made with an oath. But this (exile of Sītä) has been thought of by you through your ignorance. Let it not, however, consume you like a bamboo flower destroying the bamboo.',\n",
       " 'If, O wicked woman, Rāma has happened to do you something unbeautiful, what wrong, O base wretch, has Vaidehi done you in the world?',\n",
       " \"Of eyes expanded like those of a doe, endued with a mild temperament, and virtuous, what harm has Janaka's daughter done you.\",\n",
       " 'Surely, O nefarious one, the banishment of Ráma is enough for you. Why then do you bend your mind to perpetrate these atrocious sins?',\n",
       " 'O noble dame, having heard you asking for the banishment of Rāma, who had at first been intended by me for being installed, and who came here afterwards, I had promised you (his exile alone.)']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "english_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "734cbf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['तस्यां चीरं वसानायां नाथवत्यामनाथवत्। प्रचुक्रोश जनः सर्वो धिक् त्वां दशरथं त्विति ॥',\n",
       " 'तेन तत्र प्रणादेन दुःखितः स महीपतिः। चिच्छेद जीविते श्रद्धां धर्मे यशसि चात्मनः॥ स निःश्वस्योष्णमैक्ष्वाकस्तां भार्यामिदमब्रवीत्। कैकेयि कुशचीरेण न सीता गन्तुमर्हति॥',\n",
       " 'सुकुमारी च बाला च सततं च सुखोचिता। नेयं वनस्य योग्येति सत्यमाह गुरुर्मम ॥',\n",
       " 'इयं हि कस्यापि करोति किंचित् तपस्विनी राजवरस्य पुत्री। या चीरमासाद्य वनस्य मध्ये जाता विसंज्ञा श्रमणीव काचित्॥',\n",
       " 'चीराण्यपास्याज्जनकस्य कन्या नेयं प्रतिज्ञा मम दत्तपूर्वा। यथासुखं गच्छतु राजपुत्री वनं समग्रा सह सर्वरत्नैः॥',\n",
       " 'अजीवनाहेण मया नृशंसा कृता प्रतिज्ञा नियमेन तावत्। त्वया हि बाल्यात् प्रतिपन्नमेतत् तन्मा दहेद् वेणुमिवात्मपुष्पम्॥',\n",
       " 'रामेण यदि ते पापे किंचित्कृतमशोभनम्। अपकारः क इह ते वैदेह्या दर्शितोऽधमे॥',\n",
       " 'मृगीवोत्फुल्लनयना मृदुशीला मनस्विनी। अपकारं कमिव ते करोति जनकात्मजा॥',\n",
       " 'ननु पर्याप्तमेवं ते पापे रामविवासनम्। किमेभिः कृपणैर्भूयः पातकैरपि ते कृतैः॥',\n",
       " 'प्रतिज्ञातं मया तावत् त्वयोक्तं देवि शृण्वता। रामं यदभिषेकाय त्वमिहागतमब्रवीः॥']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanskrit_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72716a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5294, 12194)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max(len(x) for x in sanskrit_sentences), max(len(x) for x in english_sentences),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c66afe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97th percentile length sanskrit: 207.78999999999996\n",
      "97th percentile length English: 381.78999999999996\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PERCENTILE = 97\n",
    "print( f\"{PERCENTILE}th percentile length sanskrit: {np.percentile([len(x) for x in sanskrit_sentences], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7cf079c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 7108\n",
      "Number of valid sentences: 5540\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 400\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(sanskrit_sentences)):\n",
    "    sanskrit_sentence, english_sentence = sanskrit_sentences[index], english_sentences[index]\n",
    "    if is_valid_length(sanskrit_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(sanskrit_sentence, sanskrit_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(sanskrit_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9da10718",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanskrit_sentences = [sanskrit_sentences[i] for i in valid_sentence_indicies]\n",
    "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "876b7f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['तस्यां चीरं वसानायां नाथवत्यामनाथवत्। प्रचुक्रोश जनः सर्वो धिक् त्वां दशरथं त्विति ॥',\n",
       " 'तेन तत्र प्रणादेन दुःखितः स महीपतिः। चिच्छेद जीविते श्रद्धां धर्मे यशसि चात्मनः॥ स निःश्वस्योष्णमैक्ष्वाकस्तां भार्यामिदमब्रवीत्। कैकेयि कुशचीरेण न सीता गन्तुमर्हति॥',\n",
       " 'सुकुमारी च बाला च सततं च सुखोचिता। नेयं वनस्य योग्येति सत्यमाह गुरुर्मम ॥']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanskrit_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7604f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, english_sentences, sanskrit_sentences):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.sanskrit_sentences = sanskrit_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english_sentences[idx], self.sanskrit_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e45f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(english_sentences, sanskrit_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e81eb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5540"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ee12c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Aggrieved at the uproar that arose there in consequence, the lord of earth banished from his heart all regard for life, virtue, and fame. And sighing hot, that descendant of Ikşvāku spoke to that wife of his, saying, O Kaikeyi, Sītā deserves not to go in a Kuća dress.',\n",
       " 'तेन तत्र प्रणादेन दुःखितः स महीपतिः। चिच्छेद जीविते श्रद्धां धर्मे यशसि चात्मनः॥ स निःश्वस्योष्णमैक्ष्वाकस्तां भार्यामिदमब्रवीत्। कैकेयि कुशचीरेण न सीता गन्तुमर्हति॥')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c940a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 3 \n",
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f557027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('When Şītā, having a husband although seeming as if she had none, was putting on the ascetic guise, the people got into a wrath and exclaimed, “O Dasaratha, fie on you!\"', 'Aggrieved at the uproar that arose there in consequence, the lord of earth banished from his heart all regard for life, virtue, and fame. And sighing hot, that descendant of Ikşvāku spoke to that wife of his, saying, O Kaikeyi, Sītā deserves not to go in a Kuća dress.', 'Tender, and youthful, and worthy of happiness, she is by no means capable of living in the forest. My spiritual guide has spoken the truth.'), ('तस्यां चीरं वसानायां नाथवत्यामनाथवत्। प्रचुक्रोश जनः सर्वो धिक् त्वां दशरथं त्विति ॥', 'तेन तत्र प्रणादेन दुःखितः स महीपतिः। चिच्छेद जीविते श्रद्धां धर्मे यशसि चात्मनः॥ स निःश्वस्योष्णमैक्ष्वाकस्तां भार्यामिदमब्रवीत्। कैकेयि कुशचीरेण न सीता गन्तुमर्हति॥', 'सुकुमारी च बाला च सततं च सुखोचिता। नेयं वनस्य योग्येति सत्यमाह गुरुर्मम ॥')]\n",
      "[('Whom has this one injured that, being the daughter of the foremost of kings, she like a female ascetic, wearing a meagre garb in the presence of all, will (repair to the woods and) remain there like a beggar destitute of everything?', \"Let Janaka's daughter leave off her ascetic guise. This is not the promise that I had made to you before. Let the princess go to the forest in comfort, furnished with all sorts of gems.\", 'My sands run out; by me has this cruel promise been made with an oath. But this (exile of Sītä) has been thought of by you through your ignorance. Let it not, however, consume you like a bamboo flower destroying the bamboo.'), ('इयं हि कस्यापि करोति किंचित् तपस्विनी राजवरस्य पुत्री। या चीरमासाद्य वनस्य मध्ये जाता विसंज्ञा श्रमणीव काचित्॥', 'चीराण्यपास्याज्जनकस्य कन्या नेयं प्रतिज्ञा मम दत्तपूर्वा। यथासुखं गच्छतु राजपुत्री वनं समग्रा सह सर्वरत्नैः॥', 'अजीवनाहेण मया नृशंसा कृता प्रतिज्ञा नियमेन तावत्। त्वया हि बाल्यात् प्रतिपन्नमेतत् तन्मा दहेद् वेणुमिवात्मपुष्पम्॥')]\n",
      "[(\"Of eyes expanded like those of a doe, endued with a mild temperament, and virtuous, what harm has Janaka's daughter done you.\", 'Surely, O nefarious one, the banishment of Ráma is enough for you. Why then do you bend your mind to perpetrate these atrocious sins?', 'O noble dame, having heard you asking for the banishment of Rāma, who had at first been intended by me for being installed, and who came here afterwards, I had promised you (his exile alone.)'), ('मृगीवोत्फुल्लनयना मृदुशीला मनस्विनी। अपकारं कमिव ते करोति जनकात्मजा॥', 'ननु पर्याप्तमेवं ते पापे रामविवासनम्। किमेभिः कृपणैर्भूयः पातकैरपि ते कृतैः॥', 'प्रतिज्ञातं मया तावत् त्वयोक्तं देवि शृण्वता। रामं यदभिषेकाय त्वमिहागतमब्रवीः॥')]\n",
      "[(\"But since, going beyond that promise of mine, you behold Mithala's daughter dressed in mendicant garb, surely you wish to find your way to hell.\", 'Thus commissioned to the forest, Räma who was seated sealing his lips, said.', 'O righteous one, this my mother is aged and famous and of lofty spirit. May she not meet with improper treatment at your hands! It behoves you, O bestower of boons, to show greater honour to her when she shall be deprived of me and be plunged into a sea of grief and afflicted with unprecedented woe.'), ('तत्त्वेतत् समतिक्रम्य निरयं गन्तुमिच्छसि। मैथिलीमपि या हि त्वमीक्षसे चीरवासिनीम्॥', 'एवं ब्रुवन्तं पितरं रामः सम्प्रस्थितो वनम्। अवाक्शिरसमासीनमिदं वचनमब्रवीत्॥', 'इयं धार्मिक कौसल्या मम माता यशस्विनी। वृद्धा चाक्षुद्रशीला च न च त्वां देव गर्हते॥ मया विहीनां वरद प्रपन्नां शोकसागरम्। अदृष्टपूर्वव्यसनां भूयः सम्मन्तुमर्हसि ॥')]\n",
      "[('O you comparable to the mighty Indra, you should so behove with my mother smitten with my separation, that exercised by grief in consequence of my residence in the forest, she may not, renouncing life, repair to the mansions of Yama.', 'Hearing those bold words of the ascetic, the son of that foremost of men, Rāghava firm in his vows, with clasped hands answered.', 'And in the interests of Brāhmaṇas, kine, and celestials, I am ready to act as desired by you of immeasurable energy.'), ('पुत्रशोकं यथा नछेत् त्वया पूज्येन पूजिता। मां हि संचिन्तयन्ती सा त्वयि जीवेत् तपस्विनी॥ इमां महेन्द्रोपम जातगर्धिनी तथा विधातुं जननी ममार्हसि। यथा वनस्थे मयि शोककर्शिता न जीवितं न्यस्य यमक्षयं व्रजेत्॥', 'मुनेर्वचनमक्लीबं श्रुत्वा नरवरात्मजः। राघवः प्राञ्जलिर्भूत्वा प्रत्युवाच दृढव्रतः॥', 'गोब्राह्मणहितार्थाय देशस्य च हिताय च। तव चैवाप्रमेयस्य वचनं कर्तुमुद्यतः॥')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if batch_num > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7fcd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, language_to_index, start_token=True, end_token=True):\n",
    "    sentence_word_indicies = [language_to_index[token] for token in list(sentence)]\n",
    "    if start_token:\n",
    "        sentence_word_indicies.insert(0, language_to_index[START_TOKEN])\n",
    "    if end_token:\n",
    "        sentence_word_indicies.append(language_to_index[END_TOKEN])\n",
    "    for _ in range(len(sentence_word_indicies), max_sequence_length):\n",
    "        sentence_word_indicies.append(language_to_index[PADDING_TOKEN])\n",
    "    return torch.tensor(sentence_word_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd5b131b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O you comparable to the mighty Indra, you should so behove with my mother smitten with my separation, that exercised by grief in consequence of my residence in the forest, she may not, renouncing life, repair to the mansions of Yama.',\n",
       "  'Hearing those bold words of the ascetic, the son of that foremost of men, Rāghava firm in his vows, with clasped hands answered.',\n",
       "  'And in the interests of Brāhmaṇas, kine, and celestials, I am ready to act as desired by you of immeasurable energy.'),\n",
       " ('पुत्रशोकं यथा नछेत् त्वया पूज्येन पूजिता। मां हि संचिन्तयन्ती सा त्वयि जीवेत् तपस्विनी॥ इमां महेन्द्रोपम जातगर्धिनी तथा विधातुं जननी ममार्हसि। यथा वनस्थे मयि शोककर्शिता न जीवितं न्यस्य यमक्षयं व्रजेत्॥',\n",
       "  'मुनेर्वचनमक्लीबं श्रुत्वा नरवरात्मजः। राघवः प्राञ्जलिर्भूत्वा प्रत्युवाच दृढव्रतः॥',\n",
       "  'गोब्राह्मणहितार्थाय देशस्य च हिताय च। तव चैवाप्रमेयस्य वचनं कर्तुमुद्यतः॥')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6b88e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m batch[\u001b[43msentence_num\u001b[49m]\n",
      "\u001b[31mNameError\u001b[39m: name 'sentence_num' is not defined"
     ]
    }
   ],
   "source": [
    "# batch[sentence_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa6ab79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenized, kn_tokenized = [], []\n",
    "for sentence_num in range(batch_size):\n",
    "    eng_sentence, kn_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
    "    eng_tokenized.append( tokenize(eng_sentence, english_to_index, start_token=False, end_token=False) )\n",
    "    kn_tokenized.append( tokenize(kn_sentence, sanskrit_to_index, start_token=True, end_token=True) )\n",
    "eng_tokenized = torch.stack(eng_tokenized)\n",
    "kn_tokenized = torch.stack(kn_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Sanskrit to English translation, you can use the following code:\n",
    "# eng_tokenized, kn_tokenized = [], []\n",
    "# for sentence_num in range(batch_size):\n",
    "#     eng_sentence, kn_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
    "#     eng_tokenized.append( tokenize(eng_sentence, english_to_index, start_token=True, end_token=True) )\n",
    "#     kn_tokenized.append( tokenize(kn_sentence, sanskrit_to_index, start_token=False, end_token=False) )\n",
    "# eng_tokenized = torch.stack(eng_tokenized)\n",
    "# kn_tokenized = torch.stack(kn_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ada3123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 47,   1, 114,  ..., 121, 121, 121],\n",
       "        [ 40,  94,  90,  ..., 121, 121, 121],\n",
       "        [ 33, 103,  93,  ..., 121, 121, 121]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eng_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9cd9ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, kn_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
    "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
    "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    print(f\"encoder_self_attention_mask {encoder_self_attention_mask.size()}: {encoder_self_attention_mask[0, :10, :10]}\")\n",
    "    print(f\"decoder_self_attention_mask {decoder_self_attention_mask.size()}: {decoder_self_attention_mask[0, :10, :10]}\")\n",
    "    print(f\"decoder_cross_attention_mask {decoder_cross_attention_mask.size()}: {decoder_cross_attention_mask[0, :10, :10]}\")\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6baa776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_self_attention_mask torch.Size([3, 400, 400]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "decoder_self_attention_mask torch.Size([3, 400, 400]): tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "decoder_cross_attention_mask torch.Size([3, 400, 400]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]]]),\n",
       " tensor([[[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       " \n",
       "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       " \n",
       "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]]]),\n",
       " tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]]]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "create_masks(batch[0], batch[1])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfa90655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d68910f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEmbedding(nn.Module):\n",
    "    \"For a given sentence, create an embedding\"\n",
    "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(language_to_index)\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
    "        self.language_to_index = language_to_index\n",
    "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.START_TOKEN = START_TOKEN\n",
    "        self.END_TOKEN = END_TOKEN\n",
    "        self.PADDING_TOKEN = PADDING_TOKEN\n",
    "    \n",
    "    def batch_tokenize(self, batch, start_token=True, end_token=True):\n",
    "\n",
    "        def tokenize(sentence, start_token=True, end_token=True):\n",
    "            sentence_word_indicies = [self.language_to_index[token] for token in list(sentence)]\n",
    "            if start_token:\n",
    "                sentence_word_indicies.insert(0, self.language_to_index[self.START_TOKEN])\n",
    "            if end_token:\n",
    "                sentence_word_indicies.append(self.language_to_index[self.END_TOKEN])\n",
    "            for _ in range(len(sentence_word_indicies), self.max_sequence_length):\n",
    "                sentence_word_indicies.append(self.language_to_index[self.PADDING_TOKEN])\n",
    "            return torch.tensor(sentence_word_indicies)\n",
    "\n",
    "        tokenized = []\n",
    "        for sentence_num in range(len(batch)):\n",
    "           tokenized.append( tokenize(batch[sentence_num], start_token, end_token) )\n",
    "        tokenized = torch.stack(tokenized)\n",
    "        return tokenized.to(get_device())\n",
    "    \n",
    "    def forward(self, x, end_token=True): # sentence\n",
    "        x = self.batch_tokenize(x ,end_token)\n",
    "        x = self.embedding(x)\n",
    "        pos = self.position_encoder().to(get_device())\n",
    "        x = self.dropout(x + pos)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
